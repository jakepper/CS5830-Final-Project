{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS5830 Final Project\n",
    "\n",
    "## Ensemble Boosting & Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting Imports\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "\n",
    "# XG/Gamma\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_null</th>\n",
       "      <th>wave</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>d_age</th>\n",
       "      <th>d_d_age</th>\n",
       "      <th>race</th>\n",
       "      <th>race_o</th>\n",
       "      <th>samerace</th>\n",
       "      <th>...</th>\n",
       "      <th>d_expected_num_interested_in_me</th>\n",
       "      <th>d_expected_num_matches</th>\n",
       "      <th>like</th>\n",
       "      <th>guess_prob_liked</th>\n",
       "      <th>d_like</th>\n",
       "      <th>d_guess_prob_liked</th>\n",
       "      <th>met</th>\n",
       "      <th>decision</th>\n",
       "      <th>decision_o</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b''</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'female'</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>b'[4-6]'</td>\n",
       "      <td>b'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>b'European/Caucasian-American'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>b'[6-8]'</td>\n",
       "      <td>b'[5-6]'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b''</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'female'</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'[0-1]'</td>\n",
       "      <td>b'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>b'European/Caucasian-American'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>b'[6-8]'</td>\n",
       "      <td>b'[5-6]'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b''</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'female'</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'[0-1]'</td>\n",
       "      <td>b'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>b'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b'[6-8]'</td>\n",
       "      <td>b'[0-4]'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b''</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'female'</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'[2-3]'</td>\n",
       "      <td>b'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>b'European/Caucasian-American'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>b'[6-8]'</td>\n",
       "      <td>b'[5-6]'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b''</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'female'</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>b'[2-3]'</td>\n",
       "      <td>b'Asian/Pacific Islander/Asian-American'</td>\n",
       "      <td>b'Latino/Hispanic American'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'[0-3]'</td>\n",
       "      <td>b'[3-5]'</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>b'[6-8]'</td>\n",
       "      <td>b'[5-6]'</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  has_null  wave     gender   age  age_o  d_age   d_d_age  \\\n",
       "0      b''   1.0  b'female'  21.0   27.0    6.0  b'[4-6]'   \n",
       "1      b''   1.0  b'female'  21.0   22.0    1.0  b'[0-1]'   \n",
       "2      b''   1.0  b'female'  21.0   22.0    1.0  b'[0-1]'   \n",
       "3      b''   1.0  b'female'  21.0   23.0    2.0  b'[2-3]'   \n",
       "4      b''   1.0  b'female'  21.0   24.0    3.0  b'[2-3]'   \n",
       "\n",
       "                                       race  \\\n",
       "0  b'Asian/Pacific Islander/Asian-American'   \n",
       "1  b'Asian/Pacific Islander/Asian-American'   \n",
       "2  b'Asian/Pacific Islander/Asian-American'   \n",
       "3  b'Asian/Pacific Islander/Asian-American'   \n",
       "4  b'Asian/Pacific Islander/Asian-American'   \n",
       "\n",
       "                                     race_o samerace  ...  \\\n",
       "0            b'European/Caucasian-American'     b'0'  ...   \n",
       "1            b'European/Caucasian-American'     b'0'  ...   \n",
       "2  b'Asian/Pacific Islander/Asian-American'     b'1'  ...   \n",
       "3            b'European/Caucasian-American'     b'0'  ...   \n",
       "4               b'Latino/Hispanic American'     b'0'  ...   \n",
       "\n",
       "   d_expected_num_interested_in_me  d_expected_num_matches like  \\\n",
       "0                         b'[0-3]'                b'[3-5]'  7.0   \n",
       "1                         b'[0-3]'                b'[3-5]'  7.0   \n",
       "2                         b'[0-3]'                b'[3-5]'  7.0   \n",
       "3                         b'[0-3]'                b'[3-5]'  7.0   \n",
       "4                         b'[0-3]'                b'[3-5]'  6.0   \n",
       "\n",
       "  guess_prob_liked    d_like  d_guess_prob_liked  met  decision  decision_o  \\\n",
       "0              6.0  b'[6-8]'            b'[5-6]'  0.0      b'1'        b'0'   \n",
       "1              5.0  b'[6-8]'            b'[5-6]'  1.0      b'1'        b'0'   \n",
       "2              NaN  b'[6-8]'            b'[0-4]'  1.0      b'1'        b'1'   \n",
       "3              6.0  b'[6-8]'            b'[5-6]'  0.0      b'1'        b'1'   \n",
       "4              6.0  b'[6-8]'            b'[5-6]'  0.0      b'1'        b'1'   \n",
       "\n",
       "   match  \n",
       "0   b'0'  \n",
       "1   b'0'  \n",
       "2   b'1'  \n",
       "3   b'1'  \n",
       "4   b'1'  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (8378, 123)\n"
     ]
    }
   ],
   "source": [
    "dating_df = pd.read_csv('./data/speeddating.csv')\n",
    "display(dating_df.head())\n",
    "print(f'Dataset Shape: {dating_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has_null\n",
      "wave\n",
      "gender\n",
      "age\n",
      "age_o\n",
      "d_age\n",
      "d_d_age\n",
      "race\n",
      "race_o\n",
      "samerace\n",
      "importance_same_race\n",
      "importance_same_religion\n",
      "d_importance_same_race\n",
      "d_importance_same_religion\n",
      "field\n",
      "pref_o_attractive\n",
      "pref_o_sincere\n",
      "pref_o_intelligence\n",
      "pref_o_funny\n",
      "pref_o_ambitious\n",
      "pref_o_shared_interests\n",
      "d_pref_o_attractive\n",
      "d_pref_o_sincere\n",
      "d_pref_o_intelligence\n",
      "d_pref_o_funny\n",
      "d_pref_o_ambitious\n",
      "d_pref_o_shared_interests\n",
      "attractive_o\n",
      "sinsere_o\n",
      "intelligence_o\n",
      "funny_o\n",
      "ambitous_o\n",
      "shared_interests_o\n",
      "d_attractive_o\n",
      "d_sinsere_o\n",
      "d_intelligence_o\n",
      "d_funny_o\n",
      "d_ambitous_o\n",
      "d_shared_interests_o\n",
      "attractive_important\n",
      "sincere_important\n",
      "intellicence_important\n",
      "funny_important\n",
      "ambtition_important\n",
      "shared_interests_important\n",
      "d_attractive_important\n",
      "d_sincere_important\n",
      "d_intellicence_important\n",
      "d_funny_important\n",
      "d_ambtition_important\n",
      "d_shared_interests_important\n",
      "attractive\n",
      "sincere\n",
      "intelligence\n",
      "funny\n",
      "ambition\n",
      "d_attractive\n",
      "d_sincere\n",
      "d_intelligence\n",
      "d_funny\n",
      "d_ambition\n",
      "attractive_partner\n",
      "sincere_partner\n",
      "intelligence_partner\n",
      "funny_partner\n",
      "ambition_partner\n",
      "shared_interests_partner\n",
      "d_attractive_partner\n",
      "d_sincere_partner\n",
      "d_intelligence_partner\n",
      "d_funny_partner\n",
      "d_ambition_partner\n",
      "d_shared_interests_partner\n",
      "sports\n",
      "tvsports\n",
      "exercise\n",
      "dining\n",
      "museums\n",
      "art\n",
      "hiking\n",
      "gaming\n",
      "clubbing\n",
      "reading\n",
      "tv\n",
      "theater\n",
      "movies\n",
      "concerts\n",
      "music\n",
      "shopping\n",
      "yoga\n",
      "d_sports\n",
      "d_tvsports\n",
      "d_exercise\n",
      "d_dining\n",
      "d_museums\n",
      "d_art\n",
      "d_hiking\n",
      "d_gaming\n",
      "d_clubbing\n",
      "d_reading\n",
      "d_tv\n",
      "d_theater\n",
      "d_movies\n",
      "d_concerts\n",
      "d_music\n",
      "d_shopping\n",
      "d_yoga\n",
      "interests_correlate\n",
      "d_interests_correlate\n",
      "expected_happy_with_sd_people\n",
      "expected_num_interested_in_me\n",
      "expected_num_matches\n",
      "d_expected_happy_with_sd_people\n",
      "d_expected_num_interested_in_me\n",
      "d_expected_num_matches\n",
      "like\n",
      "guess_prob_liked\n",
      "d_like\n",
      "d_guess_prob_liked\n",
      "met\n",
      "decision\n",
      "decision_o\n",
      "match\n"
     ]
    }
   ],
   "source": [
    "for column in dating_df.columns:\n",
    "   print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeating Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8378, 48)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dating_df = dating_df.drop(['has_null', 'd_age', 'd_d_age', 'samerace', 'd_importance_same_race', 'd_importance_same_religion', 'd_pref_o_attractive',\n",
    "                            'd_pref_o_sincere', 'd_pref_o_intelligence', 'd_pref_o_funny', 'd_pref_o_ambitious', 'd_pref_o_shared_interests',\n",
    "                            'd_attractive_o', 'd_sinsere_o', 'd_intelligence_o', 'd_funny_o', 'd_ambitous_o', 'd_shared_interests_o',\n",
    "                            'd_attractive_important', 'd_sincere_important', 'd_intellicence_important', 'd_funny_important', 'd_ambtition_important',\n",
    "                            'd_shared_interests_important', 'd_attractive', 'd_sincere', 'd_intelligence', 'd_funny', 'd_ambition', 'd_attractive_partner', \n",
    "                            'd_sincere_partner', 'd_intelligence_partner', 'd_funny_partner', 'd_ambition_partner', 'd_shared_interests_partner',\n",
    "                            'sports', 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv', 'theater',\n",
    "                            'movies', 'concerts', 'music', 'shopping', 'yoga', 'd_sports', 'd_tvsports', 'd_exercise', 'd_dining', 'd_museums', 'd_art', 'd_hiking', \n",
    "                            'd_gaming', 'd_clubbing', 'd_reading', 'd_tv', 'd_theater', 'd_movies', 'd_concerts', 'd_music', 'd_shopping', 'd_yoga', 'd_interests_correlate', \n",
    "                            'd_expected_happy_with_sd_people', 'd_expected_num_interested_in_me', 'd_expected_num_matches', 'd_like', 'd_guess_prob_liked'\n",
    "                            ], axis=1)\n",
    "display(dating_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Null Values per Column:\n",
      "age: 95\n",
      "age_o: 104\n",
      "importance_same_race: 79\n",
      "importance_same_religion: 79\n",
      "pref_o_attractive: 89\n",
      "pref_o_sincere: 89\n",
      "pref_o_intelligence: 89\n",
      "pref_o_funny: 98\n",
      "pref_o_ambitious: 107\n",
      "pref_o_shared_interests: 129\n",
      "attractive_o: 212\n",
      "sinsere_o: 287\n",
      "intelligence_o: 306\n",
      "funny_o: 360\n",
      "ambitous_o: 722\n",
      "shared_interests_o: 1076\n",
      "attractive_important: 79\n",
      "sincere_important: 79\n",
      "intellicence_important: 79\n",
      "funny_important: 89\n",
      "ambtition_important: 99\n",
      "shared_interests_important: 121\n",
      "attractive: 105\n",
      "sincere: 105\n",
      "intelligence: 105\n",
      "funny: 105\n",
      "ambition: 105\n",
      "attractive_partner: 202\n",
      "sincere_partner: 277\n",
      "intelligence_partner: 296\n",
      "funny_partner: 350\n",
      "ambition_partner: 712\n",
      "shared_interests_partner: 1067\n",
      "interests_correlate: 158\n",
      "expected_happy_with_sd_people: 101\n",
      "expected_num_interested_in_me: 6578\n",
      "expected_num_matches: 1173\n",
      "like: 240\n",
      "guess_prob_liked: 309\n",
      "met: 375\n",
      "\n",
      "Number of Rows with NA values: 7330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Null Values per Column:\")\n",
    "null_counts = dating_df.isnull().sum()\n",
    "for col, count in null_counts.items():\n",
    "    if count > 0:\n",
    "       print(f\"{col}: {count}\")\n",
    "\n",
    "print(f\"\\nNumber of Rows with NA values: {dating_df[dating_df.isnull().any(axis=1)].shape[0]}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can't drop samples with missing values as that would lead to a significant loss of data\n",
    "\n",
    "Let's drop columns where there are over 1000 missing values and drop rows where the majority of the data is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Rows with NA values: 1912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop = [col for col, count in null_counts.items() if count > 1000]\n",
    "dating_df = dating_df.drop(columns=drop) # drop columns\n",
    "print(f\"\\nNumber of Rows with NA values: {dating_df[dating_df.isnull().any(axis=1)].shape[0]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imput the remaining missing values (using median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Rows with NA values: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = dating_df.drop(['match', 'decision', 'decision_o'], axis=1, inplace=False)\n",
    "y = dating_df['match']\n",
    "\n",
    "matches = {\"b'0'\": 0, \"b'1'\": 1}\n",
    "\n",
    "y = pd.DataFrame([matches[item] for item in y])\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "X = pd.DataFrame(imputer.fit_transform(X, y))\n",
    "\n",
    "print(f\"\\nNumber of Rows with NA values: {X[X.isnull().any(axis=1)].shape[0]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Transformations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X.columns:\n",
    "    if X[col].dtype == object:\n",
    "      encoder = OrdinalEncoder()\n",
    "      X[col] = encoder.fit_transform(X[[col]])\n",
    "        \n",
    "X.columns = dating_df.drop(['match', 'decision', 'decision_o'], axis=1, inplace=False).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wave</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>race</th>\n",
       "      <th>race_o</th>\n",
       "      <th>importance_same_race</th>\n",
       "      <th>importance_same_religion</th>\n",
       "      <th>field</th>\n",
       "      <th>pref_o_attractive</th>\n",
       "      <th>...</th>\n",
       "      <th>attractive_partner</th>\n",
       "      <th>sincere_partner</th>\n",
       "      <th>intelligence_partner</th>\n",
       "      <th>funny_partner</th>\n",
       "      <th>ambition_partner</th>\n",
       "      <th>interests_correlate</th>\n",
       "      <th>expected_happy_with_sd_people</th>\n",
       "      <th>like</th>\n",
       "      <th>guess_prob_liked</th>\n",
       "      <th>met</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   wave  gender  age  age_o  race  race_o  importance_same_race  \\\n",
       "0   0.0     0.0  3.0    9.0   1.0     3.0                   2.0   \n",
       "1   0.0     0.0  3.0    4.0   1.0     3.0                   2.0   \n",
       "2   0.0     0.0  3.0    4.0   1.0     1.0                   2.0   \n",
       "3   0.0     0.0  3.0    5.0   1.0     3.0                   2.0   \n",
       "4   0.0     0.0  3.0    6.0   1.0     4.0                   2.0   \n",
       "\n",
       "   importance_same_religion  field  pref_o_attractive  ...  \\\n",
       "0                       3.0  126.0               81.0  ...   \n",
       "1                       3.0  126.0               87.0  ...   \n",
       "2                       3.0  126.0               55.0  ...   \n",
       "3                       3.0  126.0               78.0  ...   \n",
       "4                       3.0  126.0               78.0  ...   \n",
       "\n",
       "   attractive_partner  sincere_partner  intelligence_partner  funny_partner  \\\n",
       "0                 7.0             12.0                  10.0            9.0   \n",
       "1                 9.0             10.0                  10.0           11.0   \n",
       "2                 6.0             10.0                  14.0           11.0   \n",
       "3                 9.0              7.0                  12.0            9.0   \n",
       "4                 6.0              7.0                  10.0            9.0   \n",
       "\n",
       "   ambition_partner  interests_correlate  expected_happy_with_sd_people  like  \\\n",
       "0               7.0                 79.0                            2.0  10.0   \n",
       "1               5.0                119.0                            2.0  10.0   \n",
       "2               5.0                 81.0                            2.0  10.0   \n",
       "3               7.0                126.0                            2.0  10.0   \n",
       "4               7.0                 86.0                            2.0   8.0   \n",
       "\n",
       "   guess_prob_liked  met  \n",
       "0              10.0  0.0  \n",
       "1               8.0  1.0  \n",
       "2               8.0  1.0  \n",
       "3              10.0  0.0  \n",
       "4              10.0  0.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.835283\n",
      "1    0.164717\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAZV0lEQVR4nO3df7RdZX3n8ffHID9UUkAChQQEbaoCo1giUl3jOEUl1lEY12CDP0gdnHQxTEdbrQXXLLWdpjozjlZUmGFUCC1KUy0CdnBkYh37A8VgqfySIQWETJAEEIliweB3/tjP1cPNyd03cM+5N9z3a62zzj7f/ex9nn1ucj93P3ufvVNVSJI0lSfNdgckSXOfYSFJ6mVYSJJ6GRaSpF6GhSSpl2EhSeplWEg9klyRZOU0296e5OU7mPeyJBtntnePWv8bk3xpBtd3Q5KXten3JfmTGVz3u5N8YqbWp9EzLDRtSX4w8PhJkh8NvH7jmPow5S/cJGcl+eqQ+v5JHk5y1M6+Z1W9qqrW7OxyMynJBa3/W9vj+iTvT/JzA/28qKpeOc11/UFfu6o6sqq+8ji7PvRnVlV/WFVvfbzr1vgYFpq2qnraxAO4A3jNQO2i6awjyW6j7SV/DLw4yeGT6iuA66rq+umuKJ259H/kP1fV3sAi4C3AccDfJHnqTL7JGH5G2gXNpf8I2kUlOTbJVUnuT3JXko8l2X1gfiU5I8ktwC2t9q7WdlOSt7Y2v9Dm7ZHkg0nuSHJ3kv+WZK/2S/EK4OCBPZqDB/tSVRuBLwNvntTNU4E1SfZN8oUkW5J8r00vGejrV5KsTvI3wIPAM1vtrW3+s5J8Ocm9Se5JclGSfSa91wuT3NjWf36SPXfwuR2c5HOtL7cl+ffT+byr6h+r6hvAa4Gn0wUHSX49yV+36ST5cJLNSb6f5FtJjkqyCngj8K72+V3e2t+e5HeTfAv4YZLdhgyp7ZnkT9uezTeTPH9gW37682uvL0jyBzv6mU0e1kry2nTDXve3z/u5A/NuT/LOtg3fb30Y+plqdAwLzYRHgN8C9gd+GTge+LeT2pwEvAg4Isly4LeBlwO/APyzSW3/E/CLwNFt/mLgPVX1Q+BVwKaBPZpNQ/qzhoGwSPLstq7P0P2bPx94BnAo8CPgY5OWfzOwCtgb+M6keQHeDxwMPBc4BHjfpDZvBE4AntW24z9M7mDbY7kc+Pu2fccDb09ywpDtGaqqtgJXAv90yOxXAi9t778P8GvAvVV1HnAR3V7K06rqNQPLnAK8GtinqrYNWeeJwJ8B+wGfBj6f5Mk9fez9mSX5Rbqfzdvp9pr+J3D54B8cwOuB5cDhwPOAX5/qfTXzDAs9blV1TVV9raq2VdXtwH9n+wB4f1XdV1U/ovuPf35V3VBVDwK/N9EoSYB/A/xWa78V+EO6YaTpugQ4MMmL2+tTgSuqaktV3VtVn6uqB9u6Vw/p6wWtb9uq6seTtnVDVV1ZVQ9V1RbgQ0OW/1hV3VlV97X1nzKkjy8EFlXV71fVw1V1K/A/dnI7ATbR/fKe7Md0YfccIFV1U1Xd1bOus1u/f7SD+ddU1WfbZ/IhYE+6obDH69eAv2if64+BDwJ7AS8eaHN2VW1qn+nldOGvMXJsUo9b+8vwQ8Ay4Cl0/66umdTszoHpg4H1O5i3qK3jmi43urcAFky3P1X1YJI/A05NchXdX/q/3fr6FODDdH+l7tsW2TvJgqp6ZEh/HiXJAcDZdH/N7033B9f3JjUbXP47dNs72TPohmbuH6gtAP6qdwMfbTFw3+RiVX05yceAjwOHJrkEeGdVPTDFuna43ZPnV9VP0h20HrZtO+tgBvbg2rrvpNu2Cd8dmH5wht5XO8E9C82Ec4FvA0uraiHwbrpf8IMGL298F7Bk4PUhA9P30A0NHVlV+7THz7WD6pPXM5U1dHswr6D7pf6FVn8H8GzgRa2vL231wf5O9R7vb/Of15Z/E9tv6+D2HEr31/9kdwK3DWzjPlW1d1X9av+mtQ4nT6MbyhsaMFV1dlUdAxxJNxz1OxOzdrDKvs/2p9vVhtGW8LNte5Au5Cf8/E6sdxNdeE6sO+29/l/Pchojw0IzYW/gAeAHSZ4DnN7Tfi3wliTPbX/pv2diRlX9hG445sPtr3iSLB4Yy78beHoGThndgb8C7gfOAy6uqocH+voj4P4k+wHvneY2Ttgb+EFbfjE/+wU86IwkS9r63w386ZA2VwMPtIPKeyVZ0A5Av7CvA+0EgGOAz9Pt1Zw/pM0Lk7yoHVP4IfCPdMeWoPsMn9m7pds7Jsnr0p0t9XbgIeBrbd61wBvadizn0UNzfT+ztcCrkxzf+vuOtu6/fQx91IgYFpoJ7wTeAGyl+0U/7JfjT1XVFXRDOX8JbACuarMeas+/2+pfS/IA8L/p9gaoqm/THQy9tZ05M3Q4orobtVxI9xfrhQOz/ohuPPweul90X9yJ7YTu+MovAd8H/gL48yFtPg18Cbi1Pbb7TkMb8noN3dj7ba0/nwCmCsF3JdlKN+x0Id1Q34vbQeTJFtL9LL5HN8RzL92xAIBP0p1ocH+Sz0/xfpNdSnd84Xt0JwG8buCYztva9txPN+z30/X2/cyq6ma6PbSP0n0Or6E7LfthNGfEmx9ptrXTJK8H9tjBWTiSZpl7FpoVSf5lkt2T7Et3quzlBoU0dxkWmi2/AWwB/oFuLL3vOIekWeQwlCSpl3sWkqReT9gv5e2///512GGHzXY3JGmXcs0119xTVYsm15+wYXHYYYexfv36/oaSpJ9KMvl6aIDDUJKkaTAsJEm9DAtJUi/DQpLUy7CQJPUaWVgkeXaSawceDyR5e5L9klyZ5Jb2vO/AMmcl2ZDk5sE7hiU5Jsl1bd7ZGbjRgSRp9EYWFlV1c1UdXVVHA8fQXe/+EuBMYF1VLQXWtdckOYLuLmFH0t2Y5pwkEze8OZfuNpdL22P5qPotSdreuIahjgf+oaq+Q3cf3zWtvobu3sy0+sXtdpW30V2i+tgkBwELq+qqgctOn4QkaWzGFRYr6K5nD3DgxL2A2/MBrb6YR9/WcWOrLW7Tk+uSpDEZ+Te4k+wOvBY4q6/pkFpNUR/2Xqvohqs49NBDd6KX2zvmdy7sb6R555r/cupsd0GaFePYs3gV8M2quru9vrsNLdGeN7f6Rh597+KJ+/tu5NH3ax687++jVNV5VbWsqpYtWrTdpU0kSY/ROMLiFH42BAVwGbCyTa+ku1XjRH1Fu7/w4XQHsq9uQ1VbkxzXzoI6dWAZSdIYjHQYKslTgFfQ3ehmwgeAtUlOA+4ATgaoqhuSrAVuBLYBZ7T7FEN3Y5wL6O6dfEV7SJLGZKRhUVUPAk+fVLuX7uyoYe1XA6uH1NcDR42ij5Kkfn6DW5LUy7CQJPUyLCRJvQwLSVIvw0KS1MuwkCT1MiwkSb0MC0lSL8NCktTLsJAk9TIsJEm9DAtJUi/DQpLUy7CQJPUyLCRJvQwLSVIvw0KS1MuwkCT1MiwkSb0MC0lSL8NCktRrpGGRZJ8kn03y7SQ3JfnlJPsluTLJLe1534H2ZyXZkOTmJCcM1I9Jcl2bd3aSjLLfkqRHG/WexUeAL1bVc4DnAzcBZwLrqmopsK69JskRwArgSGA5cE6SBW095wKrgKXtsXzE/ZYkDRhZWCRZCLwU+CRAVT1cVfcDJwJrWrM1wElt+kTg4qp6qKpuAzYAxyY5CFhYVVdVVQEXDiwjSRqDUe5ZPBPYApyf5O+SfCLJU4EDq+ougPZ8QGu/GLhzYPmNrba4TU+ubyfJqiTrk6zfsmXLzG6NJM1jowyL3YBfAs6tqhcAP6QNOe3AsOMQNUV9+2LVeVW1rKqWLVq0aGf7K0nagVGGxUZgY1V9vb3+LF143N2GlmjPmwfaHzKw/BJgU6svGVKXJI3JyMKiqr4L3Jnk2a10PHAjcBmwstVWApe26cuAFUn2SHI43YHsq9tQ1dYkx7WzoE4dWEaSNAa7jXj9vwlclGR34FbgLXQBtTbJacAdwMkAVXVDkrV0gbINOKOqHmnrOR24ANgLuKI9JEljMtKwqKprgWVDZh2/g/argdVD6uuBo2a0c5KkafMb3JKkXoaFJKmXYSFJ6mVYSJJ6GRaSpF6GhSSpl2EhSeplWEiSehkWkqRehoUkqZdhIUnqZVhIknoZFpKkXoaFJKmXYSFJ6mVYSJJ6GRaSpF6GhSSpl2EhSeplWEiSehkWkqReIw2LJLcnuS7JtUnWt9p+Sa5Mckt73neg/VlJNiS5OckJA/Vj2no2JDk7SUbZb0nSo41jz+KfV9XRVbWsvT4TWFdVS4F17TVJjgBWAEcCy4Fzkixoy5wLrAKWtsfyMfRbktTMxjDUicCaNr0GOGmgfnFVPVRVtwEbgGOTHAQsrKqrqqqACweWkSSNwajDooAvJbkmyapWO7Cq7gJozwe0+mLgzoFlN7ba4jY9ub6dJKuSrE+yfsuWLTO4GZI0v+024vW/pKo2JTkAuDLJt6doO+w4RE1R375YdR5wHsCyZcuGtpEk7byR7llU1ab2vBm4BDgWuLsNLdGeN7fmG4FDBhZfAmxq9SVD6pKkMRlZWCR5apK9J6aBVwLXA5cBK1uzlcClbfoyYEWSPZIcTncg++o2VLU1yXHtLKhTB5aRJI3BKIehDgQuaWe57gZ8uqq+mOQbwNokpwF3ACcDVNUNSdYCNwLbgDOq6pG2rtOBC4C9gCvaQ5I0JiMLi6q6FXj+kPq9wPE7WGY1sHpIfT1w1Ez3UZI0PX6DW5LUy7CQJPUyLCRJvQwLSVIvw0KS1MuwkCT1MiwkSb0MC0lSL8NCktTLsJAk9TIsJEm9DAtJUi/DQpLUy7CQJPUyLCRJvQwLSVIvw0KS1MuwkCT1MiwkSb0MC0lSr5GHRZIFSf4uyRfa6/2SXJnklva870Dbs5JsSHJzkhMG6sckua7NOztJRt1vSdLPjGPP4m3ATQOvzwTWVdVSYF17TZIjgBXAkcBy4JwkC9oy5wKrgKXtsXwM/ZYkNdMKiyTrplMb0mYJ8GrgEwPlE4E1bXoNcNJA/eKqeqiqbgM2AMcmOQhYWFVXVVUBFw4sI0kag92mmplkT+ApwP5tuGhi+GchcPA01v9HwLuAvQdqB1bVXQBVdVeSA1p9MfC1gXYbW+3HbXpyfVh/V9HtgXDooYdOo3uSpOno27P4DeAa4DnteeJxKfDxqRZM8i+AzVV1zTT7Muw4RE1R375YdV5VLauqZYsWLZrm20qS+ky5Z1FVHwE+kuQ3q+qjO7nulwCvTfKrwJ7AwiR/Atyd5KC2V3EQsLm13wgcMrD8EmBTqy8ZUpckjcm0jllU1UeTvDjJG5KcOvHoWeasqlpSVYfRHbj+clW9CbgMWNmaraTbS6HVVyTZI8nhdAeyr25DVluTHNfOgjp1YBlJ0hhMuWcxIckfA88CrgUeaeWJg8076wPA2iSnAXcAJwNU1Q1J1gI3AtuAM6pq4r1OBy4A9gKuaA9J0phMKyyAZcAR7WyknVZVXwG+0qbvBY7fQbvVwOoh9fXAUY/lvSVJj990v2dxPfDzo+yIJGnumu6exf7AjUmuBh6aKFbVa0fSK0nSnDLdsHjfKDshSZrbphUWVfV/Rt0RSdLcNd2zobbysy/C7Q48GfhhVS0cVcckSXPHdPcsBi/XQZKTgGNH0SFJ0tzzmK46W1WfB35lZrsiSZqrpjsM9bqBl0+i+97FY/rOhSRp1zPds6FeMzC9Dbid7pLikqR5YLrHLN4y6o5Ikuau6d78aEmSS5JsTnJ3ks+1GxtJkuaB6R7gPp/uqrAH09146PJWkyTNA9MNi0VVdX5VbWuPCwDvLiRJ88R0w+KeJG9KsqA93gTcO8qOSZLmjumGxb8GXg98F7gL+FeAB70laZ6Y7qmz/xFYWVXfA0iyH/BBuhCRJD3BTXfP4nkTQQFQVfcBLxhNlyRJc810w+JJSfadeNH2LKa7VyJJ2sVN9xf+fwX+Nsln6S7z8XqG3P5UkvTENN1vcF+YZD3dxQMDvK6qbhxpzyRJc8a0h5JaOBgQkjQPPaZLlE9Hkj2TXJ3k75PckOT3Wn2/JFcmuaU9Dx4LOSvJhiQ3JzlhoH5MkuvavLOTZFT9liRtb2RhATwE/EpVPR84Glie5DjgTGBdVS0F1rXXJDkCWAEcCSwHzkmyoK3rXGAVsLQ9lo+w35KkSUYWFtX5QXv55PYoukubr2n1NcBJbfpE4OKqeqiqbgM2AMcmOQhYWFVXVVUBFw4sI0kag1HuWdAuDXItsBm4sqq+DhxYVXcBtOcDWvPFwJ0Di29stcVtenJ92PutSrI+yfotW7bM6LZI0nw20rCoqkeq6mhgCd1ewlFTNB92HKKmqA97v/OqallVLVu0yOscStJMGWlYTKiq+4Gv0B1ruLsNLdGeN7dmG4FDBhZbAmxq9SVD6pKkMRnl2VCLkuzTpvcCXg58m+6+GCtbs5XApW36MmBFkj2SHE53IPvqNlS1Nclx7SyoUweWkSSNwSgv2XEQsKad0fQkYG1VfSHJVcDaJKcBdwAnA1TVDUnW0n2XYxtwRlU90tZ1OnABsBdwRXtIksZkZGFRVd9iyMUGq+pe4PgdLLOaIZcRqar1wFTHOyRJIzSWYxaSpF2bYSFJ6mVYSJJ6GRaSpF6GhSSpl2EhSeplWEiSehkWkqRehoUkqZdhIUnqZVhIknoZFpKkXoaFJKmXYSFJ6mVYSJJ6GRaSpF6GhSSpl2EhSeplWEiSehkWkqReIwuLJIck+cskNyW5IcnbWn2/JFcmuaU97zuwzFlJNiS5OckJA/VjklzX5p2dJKPqtyRpe6Pcs9gGvKOqngscB5yR5AjgTGBdVS0F1rXXtHkrgCOB5cA5SRa0dZ0LrAKWtsfyEfZbkjTJyMKiqu6qqm+26a3ATcBi4ERgTWu2BjipTZ8IXFxVD1XVbcAG4NgkBwELq+qqqirgwoFlJEljMJZjFkkOA14AfB04sKrugi5QgANas8XAnQOLbWy1xW16cl2SNCYjD4skTwM+B7y9qh6YqumQWk1RH/Zeq5KsT7J+y5YtO99ZSdJQIw2LJE+mC4qLqurPW/nuNrREe97c6huBQwYWXwJsavUlQ+rbqarzqmpZVS1btGjRzG2IJM1zozwbKsAngZuq6kMDsy4DVrbplcClA/UVSfZIcjjdgeyr21DV1iTHtXWeOrCMJGkMdhvhul8CvBm4Lsm1rfZu4APA2iSnAXcAJwNU1Q1J1gI30p1JdUZVPdKWOx24ANgLuKI9JEljMrKwqKq/ZvjxBoDjd7DMamD1kPp64KiZ650kaWf4DW5JUi/DQpLUy7CQJPUyLCRJvQwLSVIvw0KS1MuwkCT1MiwkSb0MC0lSL8NCktTLsJAk9TIsJEm9DAtJUq9RXqJc0ojc8fv/ZLa7oDno0PdcN7J1u2chSeplWEiSehkWkqRehoUkqZdhIUnqZVhIknoZFpKkXiMLiySfSrI5yfUDtf2SXJnklva878C8s5JsSHJzkhMG6sckua7NOztJRtVnSdJwo9yzuABYPql2JrCuqpYC69prkhwBrACObMuck2RBW+ZcYBWwtD0mr1OSNGIjC4uq+ipw36TyicCaNr0GOGmgfnFVPVRVtwEbgGOTHAQsrKqrqqqACweWkSSNybiPWRxYVXcBtOcDWn0xcOdAu42ttrhNT64PlWRVkvVJ1m/ZsmVGOy5J89lcOcA97DhETVEfqqrOq6plVbVs0aJFM9Y5SZrvxh0Wd7ehJdrz5lbfCBwy0G4JsKnVlwypS5LGaNxhcRmwsk2vBC4dqK9IskeSw+kOZF/dhqq2JjmunQV16sAykqQxGdklypN8BngZsH+SjcB7gQ8Aa5OcBtwBnAxQVTckWQvcCGwDzqiqR9qqTqc7s2ov4Ir2kCSN0cjCoqpO2cGs43fQfjWwekh9PXDUDHZNkrST5soBbknSHGZYSJJ6GRaSpF6GhSSpl2EhSeplWEiSehkWkqRehoUkqZdhIUnqZVhIknoZFpKkXoaFJKmXYSFJ6mVYSJJ6GRaSpF6GhSSpl2EhSeplWEiSehkWkqRehoUkqZdhIUnqtcuERZLlSW5OsiHJmbPdH0maT3aJsEiyAPg48CrgCOCUJEfMbq8kaf7YJcICOBbYUFW3VtXDwMXAibPcJ0maN3ab7Q5M02LgzoHXG4EXTW6UZBWwqr38QZKbx9C3+WB/4J7Z7sRckA+unO0uaHv++5zw3szEWp4xrLirhMWwT6C2K1SdB5w3+u7ML0nWV9Wy2e6HNIz/PsdjVxmG2ggcMvB6CbBplvoiSfPOrhIW3wCWJjk8ye7ACuCyWe6TJM0bu8QwVFVtS/LvgP8FLAA+VVU3zHK35hOH9jSX+e9zDFK13dC/JEmPsqsMQ0mSZpFhIUnqZVhoSl5mRXNVkk8l2Zzk+tnuy3xgWGiHvMyK5rgLgOWz3Yn5wrDQVLzMiuasqvoqcN9s92O+MCw0lWGXWVk8S32RNIsMC01lWpdZkfTEZ1hoKl5mRRJgWGhqXmZFEmBYaApVtQ2YuMzKTcBaL7OiuSLJZ4CrgGcn2ZjktNnu0xOZl/uQJPVyz0KS1MuwkCT1MiwkSb0MC0lSL8NCktTLsJDGyKv4alflqbPSmLSr+P5f4BV0347/BnBKVd04qx2TpsE9C2l8vIqvdlmGhTQ+XsVXuyzDQhofr+KrXZZhIY2PV/HVLsuwkMbHq/hql7XbbHdAmi+qaluSiav4LgA+5VV8tavw1FlJUi+HoSRJvQwLSVIvw0KS1MuwkCT1MiwkSb0MC0lSL8NCktTr/wNR9KF/nw7u1QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y.value_counts(normalize=True))\n",
    "sns.countplot(data=y, x=y[0])\n",
    "plt.title(\"Target Variable Distribution\")\n",
    "# plt.savefig(\"./figures/target-variable-dist.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation with the target variable:\n",
      "like                             0.307798\n",
      "funny_o                          0.281136\n",
      "funny_partner                    0.281131\n",
      "attractive_o                     0.265697\n",
      "attractive_partner               0.265473\n",
      "guess_prob_liked                 0.258526\n",
      "intelligence_partner             0.163643\n",
      "intelligence_o                   0.163299\n",
      "sincere_partner                  0.156626\n",
      "sinsere_o                        0.156387\n",
      "ambition_partner                 0.133600\n",
      "ambitous_o                       0.133468\n",
      "met                              0.113651\n",
      "intelligence                     0.051274\n",
      "race_o                           0.040887\n",
      "funny_important                  0.040025\n",
      "race                             0.039863\n",
      "pref_o_funny                     0.039541\n",
      "attractive                       0.035854\n",
      "intellicence_important           0.033758\n",
      "pref_o_intelligence              0.033359\n",
      "interests_correlate              0.031598\n",
      "expected_happy_with_sd_people    0.027764\n",
      "ambition                         0.011384\n",
      "ambtition_important              0.005229\n",
      "pref_o_ambitious                 0.005151\n",
      "pref_o_attractive                0.003088\n",
      "funny                            0.002860\n",
      "attractive_important             0.002718\n",
      "sincere                         -0.000047\n",
      "gender                          -0.000530\n",
      "field                           -0.004797\n",
      "wave                            -0.017404\n",
      "importance_same_religion        -0.026372\n",
      "sincere_important               -0.027418\n",
      "pref_o_sincere                  -0.028016\n",
      "age                             -0.034354\n",
      "age_o                           -0.035262\n",
      "pref_o_shared_interests         -0.048670\n",
      "shared_interests_important      -0.048832\n",
      "importance_same_race            -0.049179\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Correlation with the target variable:\")\n",
    "print(X.corrwith(y[0]).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "y_train = y_train.values.ravel()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train, y_train)\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = {\n",
    "   \"models\": [],\n",
    "   \"scores\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation F1-scores: [0.47435897 0.52895149 0.4976378  0.5095729  0.48377581]\n",
      "Average F1-score: 0.49885939377348976\n",
      "\n",
      "Logistic regression performance with class weights:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.76      0.84      1387\n",
      "           1       0.41      0.78      0.54       289\n",
      "\n",
      "    accuracy                           0.77      1676\n",
      "   macro avg       0.68      0.77      0.69      1676\n",
      "weighted avg       0.85      0.77      0.79      1676\n",
      "\n",
      "F1 score: 0.7905636235444288\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# model - Logistic Regression\n",
    "model_lr = LogisticRegression(class_weight='balanced')\n",
    "base_models['models'].append('LogisticRegression')\n",
    "\n",
    "# train / cross-validation\n",
    "cv_scores = cross_val_score(model_lr, X_train_scaled, y_train, cv=5, scoring='f1')\n",
    "print(\"Cross-validation F1-scores:\", cv_scores)\n",
    "print(\"Average F1-score:\", np.mean(cv_scores))\n",
    "print()\n",
    "\n",
    "# test\n",
    "model_lr.fit(X_train_scaled, y_train)\n",
    "y_pred = model_lr.predict(scaler.transform(X_test))\n",
    "print(\"Logistic regression performance with class weights:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"F1 score:\", f1)\n",
    "base_models['scores'].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation F1-scores: [0.5154265  0.56936937 0.52158273 0.52682927 0.55218855]\n",
      "Average F1-score: 0.5370792841882462\n",
      "\n",
      "SVC performance with class weights:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.87      1387\n",
      "           1       0.45      0.73      0.55       289\n",
      "\n",
      "    accuracy                           0.80      1676\n",
      "   macro avg       0.69      0.77      0.71      1676\n",
      "weighted avg       0.85      0.80      0.81      1676\n",
      "\n",
      "F1-score: 0.8148\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# model - Support Vector Machine Classifier\n",
    "model_svc = SVC(class_weight='balanced')\n",
    "base_models['models'].append('SVC')\n",
    "\n",
    "# train / cross-validation\n",
    "cv_scores = cross_val_score(model_svc, X_train_scaled, y_train, cv=5, scoring='f1')\n",
    "print(\"Cross-validation F1-scores:\", cv_scores)\n",
    "print(\"Average F1-score:\", np.mean(cv_scores))\n",
    "print()\n",
    "\n",
    "# test\n",
    "model_svc.fit(X_train_scaled, y_train)\n",
    "y_pred = model_svc.predict(scaler.transform(X_test))\n",
    "print(\"SVC performance with class weights:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "base_models['scores'].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation F1-scores: [0.4853229  0.50094877 0.4776699  0.50915751 0.48161765]\n",
      "Average F1-score: 0.49094334440283394\n",
      "\n",
      "Naive Bayes performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.88      1387\n",
      "           1       0.45      0.62      0.52       289\n",
      "\n",
      "    accuracy                           0.81      1676\n",
      "   macro avg       0.68      0.73      0.70      1676\n",
      "weighted avg       0.84      0.81      0.82      1676\n",
      "\n",
      "F1-score: 0.8169\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# model - Naive Bayes\n",
    "model_nb = GaussianNB()\n",
    "base_models['models'].append('GaussianNB')\n",
    "\n",
    "# train / cross-validation\n",
    "cv_scores = cross_val_score(model_nb, X_train_scaled, y_train, cv=5, scoring='f1')\n",
    "print(\"Cross-validation F1-scores:\", cv_scores)\n",
    "print(\"Average F1-score:\", np.mean(cv_scores))\n",
    "print()\n",
    "\n",
    "# test\n",
    "model_nb.fit(X_train_scaled, y_train)\n",
    "y_pred = model_nb.predict(scaler.transform(X_test))\n",
    "print(\"Naive Bayes performance:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "base_models['scores'].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation F1-scores: [0.32727273 0.32024169 0.34188034 0.34202899 0.3575419 ]\n",
      "Average F1-score: 0.3377931291889113\n",
      "\n",
      "K-Nearest Neighbors performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90      1387\n",
      "           1       0.54      0.33      0.41       289\n",
      "\n",
      "    accuracy                           0.84      1676\n",
      "   macro avg       0.71      0.64      0.66      1676\n",
      "weighted avg       0.81      0.84      0.82      1676\n",
      "\n",
      "F1-score: 0.8196\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# model - K-Nearest Neighbors\n",
    "model_knn = KNeighborsClassifier(n_neighbors=3)\n",
    "base_models['models'].append('K-Nearest Neighbors')\n",
    "\n",
    "# train / cross-validation\n",
    "cv_scores = cross_val_score(model_knn, X_train_scaled, y_train, cv=5, scoring='f1')\n",
    "print(\"Cross-validation F1-scores:\", cv_scores)\n",
    "print(\"Average F1-score:\", np.mean(cv_scores))\n",
    "print()\n",
    "\n",
    "# test\n",
    "model_knn.fit(X_train_scaled, y_train)\n",
    "y_pred = model_knn.predict(scaler.transform(X_test))\n",
    "print(\"K-Nearest Neighbors performance:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "base_models['scores'].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation F1-scores: [0.4379562  0.35046729 0.37002342 0.39090909 0.40470588]\n",
      "Average F1-score: 0.39081237731299345\n",
      "\n",
      "Decision Tree performance with class weights:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      1387\n",
      "           1       0.34      0.33      0.33       289\n",
      "\n",
      "    accuracy                           0.77      1676\n",
      "   macro avg       0.60      0.60      0.60      1676\n",
      "weighted avg       0.77      0.77      0.77      1676\n",
      "\n",
      "F1 score: 0.7711269294226317\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# model - Decision Tree Classifier\n",
    "model_dt = DecisionTreeClassifier(class_weight='balanced')\n",
    "base_models['models'].append('Decision Tree')\n",
    "\n",
    "# train / cross-validation\n",
    "cv_scores = cross_val_score(model_dt, X_train_scaled, y_train, cv=5, scoring='f1')\n",
    "print(\"Cross-validation F1-scores:\", cv_scores)\n",
    "print(\"Average F1-score:\", np.mean(cv_scores))\n",
    "print()\n",
    "\n",
    "# test\n",
    "model_dt.fit(X_train_scaled, y_train)\n",
    "y_pred = model_dt.predict(scaler.transform(X_test))\n",
    "print(\"Decision Tree performance with class weights:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"F1 score:\", f1)\n",
    "base_models['scores'].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x=base_models['models'], y=base_models['scores'])\n",
    "plt.ylim(0.6, 1.0)\n",
    "plt.savefig(\"./figures/base-model-scores.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosted Ensembles\n",
    "\n",
    "Note: AdaBoost - XGBoost - GammaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/spencerhall/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/spencerhall/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/spencerhall/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/spencerhall/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/spencerhall/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/spencerhall/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/spencerhall/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/spencerhall/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/spencerhall/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/spencerhall/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7696897374701671"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_ada = AdaBoostClassifier(model_lr, random_state=123)\n",
    "lr_ada.fit(X_train, y_train)\n",
    "lr_ada.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/spencerhall/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/spencerhall/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7440334128878282"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_ada = AdaBoostClassifier(model_lr, random_state=123, n_estimators=2)\n",
    "lr_ada.fit(X_train, y_train)\n",
    "lr_ada.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7893794749403341"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_ada = AdaBoostClassifier(model_dt, random_state=123)\n",
    "dt_ada.fit(X_train, y_train)\n",
    "dt_ada.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8514319809069213"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=-1, class_weight='balanced')\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.831145584725537"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=5, n_jobs=-1, class_weight='balanced', )\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8579952267303103"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model_log = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=123)\n",
    "xgb_model_log.fit(X_train, y_train)\n",
    "\n",
    "xgb_model_log.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8394988066825776"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model_hinge = xgb.XGBClassifier(objective=\"binary:hinge\", random_state=123)\n",
    "xgb_model_hinge.fit(X_train, y_train)\n",
    "\n",
    "xgb_model_hinge.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8585918854415274"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model_logitraw = xgb.XGBClassifier(objective=\"binary:logitraw\", random_state=123)\n",
    "xgb_model_logitraw.fit(X_train, y_train)\n",
    "\n",
    "xgb_model_logitraw.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Ensembles\n",
    "\n",
    "Note: sklearn.ensemble.BaggingClassifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
